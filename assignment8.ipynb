{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 8: Transparency of Bernoulli naive Bayes\n",
    "\n",
    "Jianwei Qian A20346099"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data set\n",
    "Statlog (German Credit Data) Data Set. <https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)>\n",
    "\n",
    "This dataset classifies people as with good or bad credit based on a set of attributes. The features include Balance of checking/saving account, Duration in month, Credit history, Credit amount, Marital status and sex, Property, Age, Housing, Job, etc. Notice ordered categorical attributes are coded as integer and unordered categorical attributes are split into multiple binary attributes.\n",
    "\n",
    "20 features, 936 instances\n",
    "\n",
    "**Categorical features:** 13 in total\n",
    "\n",
    "Chckg_acct_status, credit_hist, purpose, saving_acct_status, employ_hist, sex&marital, other_debtors, property, installment_plans, housing, job, tel_provided, foreign_worker\n",
    "\n",
    "**Continuous features:** 7 in total\n",
    "\n",
    "Duration_in_month, credit_amount, installment_rate, residence_since, age, #existing_credits, #people_liable\n",
    "\n",
    "To see detailed explanations of them, please refer to <https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)>\n",
    "\n",
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing: string -> integer\n",
    "'''infile=open('german.data.txt','r')\n",
    "outfile=open('german_numeric.csv','w')\n",
    "for line in infile:\n",
    "    items=line.split(' ')\n",
    "    for item in items:\n",
    "        if item[0]=='A':\n",
    "            item='10' if item=='A410' else item[-1] #the last char is the index of the feature value, except 'A410'\n",
    "        outfile.write(item+',')\n",
    "    #outfile.write('')\n",
    "infile.close()\n",
    "outfile.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:\n",
      "20 features, 1000 instances\n",
      "\n",
      "Head 5 lines of X:\n",
      "[[   1    6    4    3 1169    5    5    4    3    1    4    1   67    3\n",
      "     2    2    3    1    2    1]\n",
      " [   2   48    2    3 5951    1    3    2    2    1    2    1   22    3\n",
      "     2    1    3    1    1    1]\n",
      " [   4   12    4    6 2096    1    4    2    3    1    3    1   49    3\n",
      "     2    1    2    2    1    1]\n",
      " [   1   42    2    2 7882    1    4    2    3    3    4    2   45    3\n",
      "     3    1    3    2    1    1]\n",
      " [   1   24    3    0 4870    1    3    3    3    1    4    4   53    3\n",
      "     3    2    3    2    1    1]]\n",
      "\n",
      "Head 5 lines of y (1 = Good credit, -1 = Bad credit):\n",
      "[ 1. -1.  1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import csv\n",
    "import numpy as np\n",
    "reader=csv.reader(open(\"german-numeric.csv\",\"rt\"),delimiter=',')\n",
    "data=list(reader)\n",
    "Xy=np.array(data).astype('int')\n",
    "X=Xy[:,0:20]\n",
    "y=Xy[:,20]\n",
    "print('Data shape:\\n%d features, %d instances' % (len(X[0]),len(X)))\n",
    "print('\\nHead 5 lines of X:')\n",
    "print(X[:5])\n",
    "y=-2*(y-1.5) # the y values are 1's and 2's, so we need to transform them to 1's and (-1)'s\n",
    "print('\\nHead 5 lines of y (1 = Good credit, -1 = Bad credit):')\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature binarization\n",
    "Each continuous feature is binarized based on whether it is larger or smaller than its mean. Categorical features that have more than two possible values is binarized using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head 5 lines of new X:\n",
      "[[   1    0    0    0    0    0    0    0    1    0    0    0    1    0\n",
      "     0    0    0    0    0    0    0    0    0    1    0    0    0    0\n",
      "     1    0    0    1    0    1    0    0    1    0    0    0    0    0\n",
      "     1    0    1    0    0    0    1    0    0    1    1    0    6 1169\n",
      "     4    4   67    2    1]\n",
      " [   0    1    0    0    0    0    1    0    0    0    0    0    1    0\n",
      "     0    0    0    0    0    1    0    0    0    0    0    0    1    0\n",
      "     0    0    1    0    0    1    0    0    1    0    0    0    0    0\n",
      "     1    0    1    0    0    0    1    0    1    0    1    0   48 5951\n",
      "     2    2   22    1    1]\n",
      " [   0    0    0    1    0    0    0    0    1    0    0    0    0    0\n",
      "     0    1    0    0    0    1    0    0    0    0    0    0    0    1\n",
      "     0    0    0    1    0    1    0    0    1    0    0    0    0    0\n",
      "     1    0    1    0    0    1    0    0    1    0    1    0   12 2096\n",
      "     2    3   49    1    2]\n",
      " [   1    0    0    0    0    0    1    0    0    0    0    1    0    0\n",
      "     0    0    0    0    0    1    0    0    0    0    0    0    0    1\n",
      "     0    0    0    1    0    0    0    1    0    1    0    0    0    0\n",
      "     1    0    0    1    0    0    1    0    1    0    1    0   42 7882\n",
      "     2    4   45    1    2]\n",
      " [   1    0    0    0    0    0    0    1    0    1    0    0    0    0\n",
      "     0    0    0    0    0    1    0    0    0    0    0    0    1    0\n",
      "     0    0    0    1    0    1    0    0    0    0    0    1    0    0\n",
      "     1    0    0    1    0    0    1    0    1    0    1    0   24 4870\n",
      "     3    4   53    2    2]]\n"
     ]
    }
   ],
   "source": [
    "#apply one-hot encoding to categorical features\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder(categorical_features=[0,2,3,5,6,8,9,11,13,14,16,18,19])\n",
    "X1=enc.fit_transform(X).toarray().astype(int)\n",
    "print('\\nHead 5 lines of new X:')\n",
    "print(X1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values of each continuous feature:\n",
      "Duration_in_month 20.903\n",
      "credit_amount 3271.258\n",
      "installment_rate 2.973\n",
      "residence_since 2.845\n",
      "age 35.546\n",
      "#existing_credits 1.407\n",
      "#people_liable 1.155\n",
      "\n",
      "Head 5 lines of new X:\n",
      "[[1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1\n",
      "  0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0]\n",
      " [0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1\n",
      "  0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1\n",
      "  0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      "  1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1]\n",
      " [1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0\n",
      "  0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# binarize continuous features\n",
    "continuous_feat=['Duration_in_month', 'credit_amount', 'installment_rate', 'residence_since', 'age', '#existing_credits', '#people_liable']\n",
    "means=[]\n",
    "X2=np.copy(X1)\n",
    "for i in range(54,61): # the last 7 columns of X\n",
    "    m=np.mean(X1[:,i])\n",
    "    means.append(m)\n",
    "    X2[X1[:,i]>m,i]=1 #if the value is greater than mean, then set it to 1\n",
    "    X2[X1[:,i]<=m,i]=0\n",
    "\n",
    "print('Mean values of each continuous feature:')\n",
    "for i in range(len(means)):\n",
    "    print(continuous_feat[i],means[i])\n",
    "print('\\nHead 5 lines of new X:')\n",
    "print(X2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 binary features in total\n",
      "The shape of X2 is (1000, 61)\n"
     ]
    }
   ],
   "source": [
    "feat_names=[\n",
    "    'Chckg_acct_status:<0DM','Chckg_acct_status:<200DM','Chckg_acct_status:>200DM','Chckg_acct_status:no_acct',\n",
    "    'credit_hist:0','credit_hist:1','credit_hist:2','credit_hist:3','credit_hist:4',\n",
    "    'purpose:new_car','purpose:used_car','purpose:furniture','purpose:radio','purpose:appliance','purpose:repairs',\n",
    "    'purpose:education','purpose:retraining','purpose:business','purpose:other',\n",
    "    'saving_acct_status:<100DM','saving_acct_status:<500DM','saving_acct_status:<1000DM','saving_acct_status:>1000','saving_acct_status:no_acct',\n",
    "    'employ_hist:unempl','employ_hist:1year','employ_hist:4years','employ_hist:7years','employ_hist:>7years',\n",
    "    'sex&marital:M&divorced','sex&marital:F&divorced/married','sex&marital:M&single','sex&marital:M&married', #'sex&marital:F&single' doesn't exist\n",
    "    'other_debtors:none','other_debtors:co-applicant','other_debtors:guarantor',\n",
    "    'property:real_estate','property:life_insurance','property:car','property:none',\n",
    "    'installment_plans:bank','installment_plans:stores','installment_plans:none',\n",
    "    'housing:rent','housing:own','housing:free','job:unempl','job:unskilled','job:skilled','job:highly_qualified',\n",
    "    'tel_provided:none','tel_provided:yes','foreign_worker:yes','foreign_worker:no',\n",
    "    'Duration_in_month>20','credit_amount>3214.57','installment_rate>2.97','residence_since>2.85','age>35','#existing_credits>1.4','#people_liable>1'\n",
    "]\n",
    "print('%d binary features in total' % len(feat_names))\n",
    "print('The shape of X2 is', X2.shape)\n",
    "#for i in [0,2,3,5,6,8,9,11,13,14,16,18,19]:\n",
    "#    print(len(set(X[:,i])))\n",
    "#enc.n_values_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.333)\n",
    "#X_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  87.   77.   10.   29.   14.   18.  121.   16.   34.   56.   14.   41.\n",
      "   44.    3.    5.   11.    1.   24.    4.  144.   24.    8.    3.   24.\n",
      "   15.   48.   74.   24.   42.   17.   76.   95.   15.  187.   11.    5.\n",
      "   40.   44.   75.   44.   38.   13.  152.   51.  127.   25.    5.   37.\n",
      "  126.   35.  121.   82.  200.    3.  120.   89.  135.  111.   70.   61.\n",
      "   28.]\n",
      "(87,)\n",
      "(77,)\n",
      "(10,)\n",
      "Now I figured out 'feature_count_' is counting the occurrence of *positive* feature values\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf=BernoulliNB()\n",
    "clf.fit(X_train,y_train)\n",
    "ln_P_y=clf.class_log_prior_\n",
    "ln_P_x_given_y=clf.feature_log_prob_\n",
    "#print(np.exp(ln_P_x_given_y[0]))\n",
    "print(clf.feature_count_[0])\n",
    "#print(clf.class_count_)\n",
    "print(np.where(np.logical_and(X_train[:,0]==1, y_train==-1))[0].shape)\n",
    "print(np.where(np.logical_and(X_train[:,1]==1, y_train==-1))[0].shape)\n",
    "print(np.where(np.logical_and(X_train[:,2]==1, y_train==-1))[0].shape)\n",
    "print(\"Now I figured out 'feature_count_' is counting the occurrence of *positive* feature values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transparency study \n",
    "\n",
    "In each of the following sections, we will study the transparency of classifying a selected object. Specifically we will check a) the total positive log-evidence,  b) the total negative log-evidence, c) probability distribution, d) top 3 features values that contribute most to the positive evidence, e) top 3 feature values that contribute the most to the negative evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Param: obj, an array of feature values\n",
    "## Return: total log positive evidence, total log negative evidence, \n",
    "##   a list of log positive evidence shares contributed by each \"yes\" feature value, and \n",
    "##   a list of log negative evidence shares contributed by each \"no\" feature value\n",
    "def compute_total_log_evidence(obj):\n",
    "    log_pos_evidence=0\n",
    "    log_neg_evidence=0\n",
    "    contributions_yes_feat_values=[]\n",
    "    contributions_no_feat_values=[]\n",
    "    log_ratio_prior=ln_P_y[1]-ln_P_y[0]\n",
    "    \n",
    "    # add log[P(y=+1)/P(y=-1)]\n",
    "    if log_ratio_prior>0: \n",
    "        log_pos_evidence+=log_ratio_prior\n",
    "    elif log_ratio_prior<0:\n",
    "        log_neg_evidence+=log_ratio_prior\n",
    "    \n",
    "    # sum up log [P(xi|y=+1)/P(xi|y=-1)]\n",
    "    for i in range(len(obj)): \n",
    "        if obj[i]==1: #if feat value is 1, we can directly use the clf.feature_log_prob_\n",
    "            ln_ratio=ln_P_x_given_y[1,i]-ln_P_x_given_y[0,i] \n",
    "        else: #otherwise, we need to do some calculations\n",
    "            p=1-np.exp(ln_P_x_given_y[1,i])\n",
    "            n=1-np.exp(ln_P_x_given_y[0,i])\n",
    "            ln_ratio=np.log(p/n)\n",
    "        if ln_ratio>0:\n",
    "            log_pos_evidence+=ln_ratio\n",
    "            contributions_yes_feat_values.append((i,ln_ratio))\n",
    "        elif ln_ratio<0:\n",
    "            log_neg_evidence+=ln_ratio\n",
    "            contributions_no_feat_values.append((i,ln_ratio))\n",
    "    \n",
    "    return log_pos_evidence, log_neg_evidence, contributions_yes_feat_values, contributions_no_feat_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) The most positive object with respect to the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of the most positive object is 159\n",
      "a) the total positive log-evidence is 9.294994\n",
      "b) the total negative log-evidence is -1.445884\n",
      "c) the class probability distribution is [  3.899467e-04   9.996101e-01]\n",
      "\n",
      "d) top 3 features values that contribute most to the positive evidence:\n",
      "Chckg_acct_status:no_acct ✓ \t\t\t 1.22866541692\n",
      "saving_acct_status:>1000 ✓ \t\t\t 1.05062652191\n",
      "foreign_worker:no ✓ \t\t\t 0.736968963059\n",
      "\n",
      "e) top 3 features values that contribute most to the negative evidence:\n",
      "credit_hist:4 ✗ \t\t\t -0.233388990085\n",
      "property:real_estate ✗ \t\t\t -0.152721087018\n",
      "saving_acct_status:no_acct ✗ \t\t\t -0.142014716402\n",
      "\n",
      " ✓ represents feature=1, ✗ represents feature=0\n"
     ]
    }
   ],
   "source": [
    "k=3 #top-k pos/neg feature values\n",
    "prob_dists=clf.predict_proba(X_test)\n",
    "#max_indices=np.argmax(prob_dists,axis=0)\n",
    "most_pos=np.argmax(prob_dists[:,1])\n",
    "print('The index of the most positive object is %d'% most_pos)\n",
    "results=compute_total_log_evidence(X_test[most_pos])\n",
    "print('a) the total positive log-evidence is %f' % results[0])\n",
    "print('b) the total negative log-evidence is %f' % results[1])\n",
    "print('c) the class probability distribution is', prob_dists[most_pos])\n",
    "\n",
    "#find the indices of top 3 positive feature values based on the list 'contributions_yes_feat_values'\n",
    "top3_pos_feat_idx_contrib=sorted(results[2], key=lambda x: -x[1])[:k] \n",
    "print('\\nd) top %d features values that contribute most to the positive evidence:' % k)\n",
    "for (i,contrib) in top3_pos_feat_idx_contrib:\n",
    "    print(feat_names[i],'✓' if X_test[most_pos][i] else '✗','\\t\\t\\t',contrib)\n",
    "\n",
    "top3_neg_feat_idx_contrib=sorted(results[3], key=lambda x: x[1])[:k] \n",
    "print('\\ne) top %d features values that contribute most to the negative evidence:' % k)\n",
    "for (i,contrib) in top3_neg_feat_idx_contrib:\n",
    "    print(feat_names[i],'✓' if X_test[most_pos][i] else '✗','\\t\\t\\t',contrib)\n",
    "    \n",
    "print('\\n ✓ represents feature=1, ✗ represents feature=0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) The most negative object with respect to the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of the most negative object is 262\n",
      "a) the total positive log-evidence is 2.868176\n",
      "b) the total negative log-evidence is -8.194982\n",
      "c) the class probability distribution is [ 0.995164  0.004836]\n",
      "\n",
      "d) top 3 features values that contribute most to the positive evidence:\n",
      "employ_hist:7years ✓ \t\t\t 0.503243302415\n",
      "Chckg_acct_status:<0DM ✗ \t\t\t 0.346239553605\n",
      "credit_amount>3214.57 ✗ \t\t\t 0.167233493547\n",
      "\n",
      "e) top 3 features values that contribute most to the negative evidence:\n",
      "credit_hist:1 ✓ \t\t\t -1.36771936136\n",
      "property:none ✓ \t\t\t -0.657546231205\n",
      "installment_plans:bank ✓ \t\t\t -0.552911668393\n"
     ]
    }
   ],
   "source": [
    "most_neg=np.argmax(prob_dists[:,0])\n",
    "print('The index of the most negative object is %d'% most_neg)\n",
    "results=compute_total_log_evidence(X_test[most_neg])\n",
    "print('a) the total positive log-evidence is %f' % results[0])\n",
    "print('b) the total negative log-evidence is %f' % results[1])\n",
    "print('c) the class probability distribution is', prob_dists[most_neg])\n",
    "\n",
    "#find the indices of top 3 positive feature values based on the list 'contributions_yes_feat_values'\n",
    "top3_pos_feat_idx_contrib=sorted(results[2], key=lambda x: -x[1])[:k] \n",
    "print('\\nd) top %d features values that contribute most to the positive evidence:' % k)\n",
    "for (i,contrib) in top3_pos_feat_idx_contrib:\n",
    "    print(feat_names[i],'✓' if X_test[most_neg][i] else '✗','\\t\\t\\t',contrib)\n",
    "\n",
    "top3_neg_feat_idx_contrib=sorted(results[3], key=lambda x: x[1])[:k] \n",
    "print('\\ne) top %d features values that contribute most to the negative evidence:' % k)\n",
    "for (i,contrib) in top3_neg_feat_idx_contrib:\n",
    "    print(feat_names[i],'✓' if X_test[most_neg][i] else '✗','\\t\\t\\t',contrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) The object that has the largest positive evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first we compute the pos/neg evidence for all objects in the test set.\n",
    "pos_evidence_of_all_obj=[]\n",
    "neg_evidence_of_all_obj=[]\n",
    "for obj in X_test:\n",
    "    results=compute_total_log_evidence(obj)\n",
    "    pos_evidence_of_all_obj.append(results[0])\n",
    "    neg_evidence_of_all_obj.append(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of the object with the largest positive evidence is 159\n",
      "a) the total positive log-evidence is 9.294994\n",
      "b) the total negative log-evidence is -1.445884\n",
      "c) the class probability distribution is [  3.899467e-04   9.996101e-01]\n",
      "\n",
      "d) top 3 features values that contribute most to the positive evidence:\n",
      "Chckg_acct_status:no_acct ✓ \t\t\t 1.22866541692\n",
      "saving_acct_status:>1000 ✓ \t\t\t 1.05062652191\n",
      "foreign_worker:no ✓ \t\t\t 0.736968963059\n",
      "\n",
      "e) top 3 features values that contribute most to the negative evidence:\n",
      "credit_hist:4 ✗ \t\t\t -0.233388990085\n",
      "property:real_estate ✗ \t\t\t -0.152721087018\n",
      "saving_acct_status:no_acct ✗ \t\t\t -0.142014716402\n"
     ]
    }
   ],
   "source": [
    "idx=np.argmax(pos_evidence_of_all_obj)\n",
    "print('The index of the object with the largest positive evidence is %d'% idx)\n",
    "results=compute_total_log_evidence(X_test[idx])\n",
    "print('a) the total positive log-evidence is %f' % results[0])\n",
    "print('b) the total negative log-evidence is %f' % results[1])\n",
    "print('c) the class probability distribution is', prob_dists[idx])\n",
    "\n",
    "#find the indices of top 3 positive feature values based on the list 'contributions_yes_feat_values'\n",
    "top3_pos_feat_idx_contrib=sorted(results[2], key=lambda x: -x[1])[:k] \n",
    "print('\\nd) top %d features values that contribute most to the positive evidence:' % k)\n",
    "for (i,contrib) in top3_pos_feat_idx_contrib:\n",
    "    print(feat_names[i],'✓' if X_test[idx][i] else '✗','\\t\\t\\t',contrib)\n",
    "\n",
    "top3_neg_feat_idx_contrib=sorted(results[3], key=lambda x: x[1])[:k] \n",
    "print('\\ne) top %d features values that contribute most to the negative evidence:' % k)\n",
    "for (i,contrib) in top3_neg_feat_idx_contrib:\n",
    "    print(feat_names[i],'✓' if X_test[idx][i] else '✗','\\t\\t\\t',contrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)The object that has the largest (in magnitude) negative evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of the object with the largest (in magnitude) negative evidence is 199\n",
      "a) the total positive log-evidence is 3.516410\n",
      "b) the total negative log-evidence is -8.354158\n",
      "c) the class probability distribution is [ 0.992137  0.007863]\n",
      "\n",
      "d) top 3 features values that contribute most to the positive evidence:\n",
      "purpose:radio ✓ \t\t\t 0.369374129007\n",
      "Duration_in_month>20 ✗ \t\t\t 0.304835607869\n",
      "sex&marital:M&single ✓ \t\t\t 0.249265756714\n",
      "\n",
      "e) top 3 features values that contribute most to the negative evidence:\n",
      "credit_hist:1 ✓ \t\t\t -1.36771936136\n",
      "Chckg_acct_status:<0DM ✓ \t\t\t -0.798702799135\n",
      "property:none ✓ \t\t\t -0.657546231205\n"
     ]
    }
   ],
   "source": [
    "idx=np.argmin(neg_evidence_of_all_obj)\n",
    "print('The index of the object with the largest (in magnitude) negative evidence is %d'% idx)\n",
    "results=compute_total_log_evidence(X_test[idx])\n",
    "print('a) the total positive log-evidence is %f' % results[0])\n",
    "print('b) the total negative log-evidence is %f' % results[1])\n",
    "print('c) the class probability distribution is', prob_dists[idx])\n",
    "\n",
    "#find the indices of top 3 positive feature values based on the list 'contributions_yes_feat_values'\n",
    "top3_pos_feat_idx_contrib=sorted(results[2], key=lambda x: -x[1])[:k] \n",
    "print('\\nd) top %d features values that contribute most to the positive evidence:' % k)\n",
    "for (i,contrib) in top3_pos_feat_idx_contrib:\n",
    "    print(feat_names[i],'✓' if X_test[idx][i] else '✗','\\t\\t\\t',contrib)\n",
    "\n",
    "top3_neg_feat_idx_contrib=sorted(results[3], key=lambda x: x[1])[:k] \n",
    "print('\\ne) top %d features values that contribute most to the negative evidence:' % k)\n",
    "for (i,contrib) in top3_neg_feat_idx_contrib:\n",
    "    print(feat_names[i],'✓' if X_test[idx][i] else '✗','\\t\\t\\t',contrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) The most uncertain object (the probabilities are closest to 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of the most uncertain object is 332\n",
      "a) the total positive log-evidence is 4.410852\n",
      "b) the total negative log-evidence is -4.432977\n",
      "c) the class probability distribution is [ 0.505531  0.494469]\n",
      "\n",
      "d) top 3 features values that contribute most to the positive evidence:\n",
      "saving_acct_status:no_acct ✓ \t\t\t 0.669478721457\n",
      "saving_acct_status:<100DM ✗ \t\t\t 0.496125834646\n",
      "Chckg_acct_status:<0DM ✗ \t\t\t 0.346239553605\n",
      "\n",
      "e) top 3 features values that contribute most to the negative evidence:\n",
      "Chckg_acct_status:no_acct ✗ \t\t\t -0.534923175345\n",
      "housing:rent ✓ \t\t\t -0.468354280364\n",
      "Chckg_acct_status:<200DM ✓ \t\t\t -0.459385610382\n"
     ]
    }
   ],
   "source": [
    "most_uncertain=np.argmin(abs(prob_dists[:,0]-prob_dists[:,1]))\n",
    "print('The index of the most uncertain object is %d'% most_uncertain)\n",
    "results=compute_total_log_evidence(X_test[most_uncertain])\n",
    "print('a) the total positive log-evidence is %f' % results[0])\n",
    "print('b) the total negative log-evidence is %f' % results[1])\n",
    "print('c) the class probability distribution is', prob_dists[most_uncertain])\n",
    "\n",
    "#find the indices of top 3 positive feature values based on the list 'contributions_yes_feat_values'\n",
    "top3_pos_feat_idx_contrib=sorted(results[2], key=lambda x: -x[1])[:k] \n",
    "print('\\nd) top %d features values that contribute most to the positive evidence:' % k)\n",
    "for (i,contrib) in top3_pos_feat_idx_contrib:\n",
    "    print(feat_names[i],'✓' if X_test[most_uncertain][i] else '✗','\\t\\t\\t',contrib)\n",
    "\n",
    "top3_neg_feat_idx_contrib=sorted(results[3], key=lambda x: x[1])[:k] \n",
    "print('\\ne) top %d features values that contribute most to the negative evidence:' % k)\n",
    "for (i,contrib) in top3_neg_feat_idx_contrib:\n",
    "    print(feat_names[i],'✓' if X_test[most_uncertain][i] else '✗','\\t\\t\\t',contrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
